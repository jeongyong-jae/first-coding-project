{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3abe5696",
   "metadata": {},
   "source": [
    "## 예측 애널리틱스 : 부스팅\n",
    "\n",
    "# ■ 실습 목표\n",
    "      여러가지 부스팅 모델을 구현하고 예측 성능 및 학습 상태를 관찰\n",
    "      \n",
    "  ※ 부스팅\n",
    "  * 앙상블 계열의 모델로 여러 모델의 예측 결과를 종합하여 단일 모델보다 예측력이 우수함\n",
    "  * 약한 분류기(Weak learner)들을 활용하여 모델 성능을 점진적으로 개선시키는 모델\n",
    " \n",
    " ### 1. 모듈 및 데이터 불러오기\n",
    " \n",
    " #### 1.1 모듈불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2746d1fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1936/903242671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdaBoostClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGradientBoostingClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m \u001b[1;31m# 패키지를 설체하세요 ~ [pip install lightgbm]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m \u001b[1;31m# 패키지를 설치하세요 ~ [pip install catboost]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 기계학습 모델 생성, 학습 ,평가\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier # 패키지를 설체하세요 ~ [pip install lightgbm]\n",
    "from catboost import CatBoostClassifier # 패키지를 설치하세요 ~ [pip install catboost]\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "device = torch.cuda.is_available() # Catboost와 Lightgbm은 gpu 사용이 가능합니다 ! cuda 설치가 되어있다면 활용하면 좋습니다!\n",
    "\n",
    "# 시각화 & 편의용\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 한글 폰트 설정\n",
    "plt.rc('font', family='Malgun Gothic')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e25b380",
   "metadata": {},
   "source": [
    "#### 1.2 Wine 데이터 : 와인에 대한 화학적 성분들을 기반하여 와인의 품질의 예측\n",
    "\n",
    "##### 설명변수 및 반응변수\n",
    " * fixed acidity - 고정산, 와인의 산도와 연관됨 (연속형)\n",
    " * volatile acidity - 휘발산, 와인의 향과 연관됨(연속형)\n",
    " * critic acid - 구연산, 와인의 신선함을 올림(연속형)\n",
    " * residual sugar - 잔여 당분, 와인의 단 맛을 올림 (연속형)\n",
    " * chlorides - 염화물, 와인의 짠 맛의 원인(연속형)\n",
    " * free sulfur dioxide - 황 화합물, 와인을 오래 보관하게 함(연속형) \n",
    " * total sulfur dioxide - 황 화합물, 와인을 오래 보관하게 함(연속형)\n",
    " * density - 밀도, 와인의 무게감을 나타냄(연속형) \n",
    " * pH - 산성도, 와인의 신 맛의 정도(연속형)\n",
    " * sulphates - 황 화합물, 와인을 오래 보관하게 함(연속형) \n",
    " * alcohol - 알코올, 와인의 단 맛과 무게감에 영향(연속형)\n",
    " * quality - 와인등급[타겟변수](10 class 범주형)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b17e3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://s3.amazonaws.com/assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "data = pd.read_csv(url, sep=';')\n",
    "X, y = data.drop(['quality'],axis=1) , data['quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4719b744",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c88b37",
   "metadata": {},
   "source": [
    "### 2 여러가지 부스팅 모델에 대한 학습 방법 및 하이퍼파라미터 소개\n",
    "\n",
    "#### 2.1 하이퍼 파라미터 소개\n",
    "\n",
    "# ■ 하이퍼파라미터 소개\n",
    "      부스팅 모델의 과적합 발생 가능성을 제어하기 위해 하이퍼파라미터 조절은 필수임\n",
    "      \n",
    " ※ 과적합 방지를 위해 주로 탐색하는 하이퍼파라미터\n",
    "   * Learning rate : 부스팅에 대한 Regulation(Shrinkage) 효과를 지님  \n",
    "   * N_estimators : 부스팅에 활용될 예측 모델의 총 개수\n",
    "   * Subsample : 다음 시점의 약 분류기가 학습할 데이터의 비율을 의미하며 0과 1사이의 값을 가짐\n",
    "   * Max depth : 약한 분류기 모델의 복잡도를 결정하는 값으로 주로 작은 값(1~5)에서 결정됨\n",
    "   \n",
    "#### 2.2 모델 특징 소개\n",
    "\n",
    "# ■ 모델 특징 소개\n",
    "\n",
    "※ Adaboost\n",
    "  * 이전 분류기가 예측하지 못한 데이터에 높은 가중치를 둠으로써 다음 차례의 모델은 예측할수 있도록 설계된 모델\n",
    " \n",
    "※ GBM\n",
    "  * 이전 분류기가 예측하지 못한 에러(gradient)를 다음 차례의 모델이 학습하도록 설계된 모델\n",
    "  \n",
    "※ Light GBM\n",
    " * 분류기 모델이 의사결정 규칙을 찾을 때, 모든 feature와 data index에 대해 탐색하는 비효율성을 개선\n",
    " ▶ Exclusive feature bundling과 Gradient based one side sampling로 비효율성 개선\n",
    " \n",
    "※ Catboost\n",
    " * 범주형 변수가 많을 때 효율적이며 Target leakage와 prediction shift 문제점을 해결\n",
    " ▶ Exclusive feature bundling과 Gradient based one side sampling로 비효율성 개선\n",
    " \n",
    "#### 2.3 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e951fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 탐색하고자 하는 하이퍼파라미터 설정 ##\n",
    "model_params = {\"GBM\": {'model': GradientBoostingClassifier(random_state=0),\n",
    "                       'params': {'learning_rate':[0.2*(i+1) for i in range(3)],\n",
    "                                 'subsample':[0.5,0.75,1.0],\n",
    "                                 'max_depth': [i for i in range(1,11,2)]}},\n",
    "               \"AdaBoost\": {'model': AdaBoostClassifier(random_state=0),\n",
    "                       'params': {'base_estimator':[DecisionTreeClassifier(max_depth=i) for i in range(1,11,2)],\n",
    "                                 'n_estimators':[50*(i+1) for i in range(3)],\n",
    "                                 'learning_rate':[0.2*(i+1) for i in range(3)]}},\n",
    "                \"LightGBM\": {'model': LGBMClassifier(random_state=0, silent=True,device='gpu') if device == True else LGBMClassifier,\n",
    "                       'params': {'max_depth':[i for i in range(1,11,2)],\n",
    "                                 'n_estimators':[50*(i+1) for i in range(3)],\n",
    "                                 'learning_rate':[0.2*(i+1) for i in range(3)]}},\n",
    "               \"Catboost\": {'model': CatBoostClassifier(random_seed=0,silent=True, task_type ='GPU',thread_count=5),\n",
    "                       'params': {'max_depth':[i for i in range(1,11,2)] ,\n",
    "                                 'n_estimators':[50*(i+1) for i in range(3)],\n",
    "                                 'learning_rate':[0.2*(i+1) for i in range(3)]\n",
    "                                 }}\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67be5921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds = [0 for i in range(10)]\n",
    "seeds = [0]\n",
    "pbar = tqdm(total=len(model_params)*len(seeds))\n",
    "output = pd.DataFrame([])\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 2, random_state = seed)\n",
    "    \n",
    "    scaler = StandardScaler\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for model_name, v in model_params.items():\n",
    "        \n",
    "        pbar.set_description(desc=f\"{model_name}\")\n",
    "        model, params = v['model'], v['params']\n",
    "        gcv = GridSearchCV(estimator=model, param_grid=params, n_jobs=2 if model_name == 'Catboost' else 5, cv=5,scoring='accuracy')\n",
    "        gcv.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        result = pd.DataFrame.from_dict(gcv.cv_results_)\n",
    "        result['test_accuracy_with_best_hyp'] = accuracy_score(y_pred = gcv.predict(X_test_scaled) , y_true =  y_test)\n",
    "        result['model_name'] = model_name\n",
    "        result['seed'] = seed\n",
    "        output = pd.concat([output,result])\n",
    "        pbar.update(1)\n",
    "\n",
    "output.reset_index(drop=True)\n",
    "output.to_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96398ed6",
   "metadata": {},
   "source": [
    "#### 2.4 학습 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3173492",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('/classification_result.csv',index_col=0)\n",
    "model_name = 'Catboost' #GBM , AdaBoost, Light GBM, Catboost\n",
    "\n",
    "for_plot_values = output.loc[ output['model_name'] == model_name,:] #  예측 모델별 결과 확인을 위한 indexing\n",
    "fig , axs = plt.subplots(nrows=model_params[model_name]['params'],keys(),__len(), nols=1, figsize=(50,80)) # plot configur\n",
    "fig.suptitle(f'{model_name} performance for each hyperparameter', fontsize=50) # 전체 Plot 제목\n",
    "\n",
    "for ind, param_key in enumerate(model_params[model_name]['params'].keys()):\n",
    "    \n",
    "    param_for_plot = for_plot_values.groupby([f'param_{param_key}'])['mean_test_score'].mean() # 조절 하이퍼파라미터 이외에 다른\n",
    "    \n",
    "    axs[ind].bar(height = param_for_plot.values,x = [i for i in range(param_for_plot.values.shape[0])]) # bar plot\n",
    "    axs[ind].tick_params(axis='both',labelsize=20) # x,y 축 글씨 폰트 설정\n",
    "    \n",
    "    axs[ind].set_xticks([i for i in range(param_for_plot.values.shape[0])]) # x 축 ticks 설정\n",
    "    axs[ind].set_xtickslabels(param_for_plot.index.to_list()) # x 축 ticks 이름 설정\n",
    "    \n",
    "    axs[ind].set_title(f'{param_key}',fontsize=50) # 내부 plot 제목"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f598d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "output.groupby(['model_name'])['mean_test_score'].max().plot.bar()\n",
    "plt.title('Predictive performance of models with optimal hyperparameters', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57951fb0",
   "metadata": {},
   "source": [
    "#### 2.5 하이퍼파라미터 세밀하게 탐색(your option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18540ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추가 하이퍼파라미터 탐색 ( 촘촘하게 )\n",
    "model_params = {\"GBM\": {'model': GradientBoostingClassifier(random_state=0),\n",
    "                       'params': {'learning_rate':list(np.arange(0.05,0.20,0.01)), #0.2 근처 혹은 작을수록 좋은 성능을 보였다\n",
    "                                 'n_estimators' : [50] , # 너무 많은 모델 개수를 필요로 하지 않아 보였음 (50에서 가장 Best)\n",
    "                                 'subsample':[1.0], # 1에 가까울수록 좋은 성능을 보였음\n",
    "                                 'max_depth': [7,8,9] # 7과 9 사이에서 조밀하게 탐색\n",
    "                                 }},\n",
    "                \n",
    "               \"AdaBoost\": {'model': AdaBoostClassifier(random_state=0),\n",
    "                       'params': {'base_estimator':[DecisionTreeClassifier(max_depth=i) for i in [7,8,9]], # 7과 9사이에\n",
    "                                 'n_estimators':[50], # 너무 많은 모델 개수를 필요로 하지 않아 보였음 (50에서 가장 Best)\n",
    "                                 'learning_rate':list(np.arange(0.05,0.20,0.01))}},\n",
    "                \n",
    "                \"LightGBM\": {'model': LGBMClassifier(random_state=0, silent=True,device='gpu') if device == True else LG~~~~,\n",
    "                       'params': {'max_depth':[1,2,3],\n",
    "                                 'n_estimators':[100],\n",
    "                                 'learning_rate':list(np.arange(0.05,0.20,0.01))}}, # 작을수록 좋은 성능을 보였음\n",
    "                \n",
    "               \"Catboost\": {'model': CatBoostClassifier(random_seed=0,silient=True, task_type ='GPU',thread_count=5,~~~~~),\n",
    "                       'params': {'max_depth':[8,9,10] ,\n",
    "                                 'n_estimators':[150],\n",
    "                                 'learning_rate': list(np.arange(0.05,0.20,0.05)) # 다른 모델보단 성능에 둔감하게 영향을\n",
    "                                 }}}\n",
    "\n",
    "# Train\n",
    "# seeds = [0 for i in range(10)]\n",
    "seeds = [0]\n",
    "pbar = tqdm(total=len(model_params)*len(seeds))\n",
    "output = pd.DataFrame([])\n",
    "\n",
    "for seed in seeds:\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 2 , random_state =seed)\n",
    "    \n",
    "    scaler = StandardScaler\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    for model_name, v in model_params.items():\n",
    "        \n",
    "        pbar.set_description(desc=f\"{model_name}\")\n",
    "        model, params = v['model'], v['params']\n",
    "        gcv = GridSearchCV(estimator=model, param_grid_params, n_jobs=2 if model_name == 'Catboost' else 5, cv=5,scoring='a~~~')\n",
    "        gcv.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        result = pd.DataFrame.from_dict(gcv.cv_results_)\n",
    "        result['test_accuracy_with_best_hyp'] = accuracy_score(y_pred = gcv.predict(X_test_scaled) , y_true =  y_test)\n",
    "        result['model_name'] = model_name\n",
    "        result['seed'] = seed\n",
    "        output = pd.concat([output,result])\n",
    "        pbar.update(1)\n",
    "\n",
    "output.reset_index(drop=True)\n",
    "output.to_csv('./classification_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa18cb29",
   "metadata": {},
   "source": [
    "#### 2.6 테스팅 데이터에 대한 최종 예측 성능 관찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de83cc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.read_csv('/classification_result.csv',index_col=0)\n",
    "output.reset_index(drop=True, inplace=True) # index 초기화\n",
    "plt.figure(figsize=(10,10))\n",
    "idx = output.groupby(['model_name'])['mean_test_score'].idxmax() # 각 모델별로 검증용 accuracy를 기준하여, Best 성능 기록한\n",
    "output.loc[idx,['model_name','test_accuracy_with_best_hyp']].set_index('model_name').plot.bar(legend=False)\n",
    "plt.title('Predictive performance of models with optimal hyperparameters', fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe82b5d",
   "metadata": {},
   "source": [
    "## E.O.D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216f01ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
